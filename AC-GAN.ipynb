{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"colab_type":"code","executionInfo":{"elapsed":2667,"status":"ok","timestamp":1595106112544,"user":{"displayName":"sajjad savoji","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjicafS5-Ep5AreuuDxBM5Yk0bzzzKRXLzO8uc=s64","userId":"01019297866349987175"},"user_tz":-270},"id":"WOFTfUKMu6eC","outputId":"c1b5c434-252e-40a8-df32-f99f6c9024ca"},"outputs":[],"source":["from numpy import zeros\n","from numpy import ones\n","from numpy import expand_dims\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras.datasets.fashion_mnist import load_data\n","from keras.optimizers import Adam\n","from keras.models import Model\n","from keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n","from keras.layers import LeakyReLU, BatchNormalization, Dropout, Embedding\n","from keras.layers import Activation, Concatenate \n","from keras.initializers import RandomNormal\n","from matplotlib import pyplot\n","from keras.utils import to_categorical, Progbar\n","from keras.datasets import cifar10\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":2658,"status":"ok","timestamp":1595106112546,"user":{"displayName":"sajjad savoji","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjicafS5-Ep5AreuuDxBM5Yk0bzzzKRXLzO8uc=s64","userId":"01019297866349987175"},"user_tz":-270},"id":"GYFsxX-9xCG0"},"outputs":[],"source":["def define_discriminator(in_shape=(32,32,3), n_classes=10):\n","\n","    init = RandomNormal(stddev=0.02)\n","    # image input\n","    in_image = Input(shape=in_shape)\n","    # layer 1\n","    fe = Conv2D(16, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    fe = Dropout(0.5)(fe)\n","    # layer 2\n","    fe = Conv2D(32, (3,3), padding='same', kernel_initializer=init)(fe)\n","    fe = BatchNormalization()(fe)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    fe = Dropout(0.5)(fe)\n","    # layer 3\n","    fe = Conv2D(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(fe)\n","    fe = BatchNormalization()(fe)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    fe = Dropout(0.5)(fe)\n","    # layer 4\n","    fe = Conv2D(128, (3,3), padding='same', kernel_initializer=init)(fe)\n","    fe = BatchNormalization()(fe)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    fe = Dropout(0.5)(fe)\n","    # layer 5\n","    fe = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(fe)\n","    fe = BatchNormalization()(fe)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    fe = Dropout(0.5)(fe)\n","    # layer 6\n","    fe = Conv2D(128, (3,3), padding='same', kernel_initializer=init)(fe)\n","    fe = BatchNormalization()(fe)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    fe = Dropout(0.5)(fe)\n","\n","    fe = Flatten()(fe)\n","    # real/fake output\n","    out1 = Dense(1, activation='sigmoid')(fe)\n","    # class label output\n","    out2 = Dense(n_classes, activation='softmax')(fe)\n"," \n","    model = Model(in_image, [out1, out2])\n","\n","    opt = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999)\n","    model.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=opt)\n","    return model"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":2654,"status":"ok","timestamp":1595106112548,"user":{"displayName":"sajjad savoji","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjicafS5-Ep5AreuuDxBM5Yk0bzzzKRXLzO8uc=s64","userId":"01019297866349987175"},"user_tz":-270},"id":"beWgZt48zApK"},"outputs":[],"source":["def define_generator(latent_dim, n_classes=10):\n","    \n","    init = RandomNormal(stddev=0.02)\n","    # label input\n","    in_label = Input(shape=(n_classes,))\n","    in_lat = Input(shape=(latent_dim,))\n","    # layer 1\n","    merge = Concatenate()([in_lat, in_label])\n","    n_nodes = 384 \n","    gen = Dense(n_nodes, kernel_initializer=init)(merge)\n","    gen = Activation('relu')(gen)\n","    gen = Reshape((1, 1, 384))(gen)\n","    # layer 2\n","    gen = Conv2DTranspose(192, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n","    gen = BatchNormalization()(gen)\n","    gen = Activation('relu')(gen)\n","    # layer 3\n","    gen = Conv2DTranspose(96, (5,5), strides=(4,4), padding='same', kernel_initializer=init)(gen)\n","    gen = BatchNormalization()(gen)\n","    gen = Activation('relu')(gen)\n","    # layer 4\n","    gen = Conv2DTranspose(3, (5,5), strides=(4,4), padding='same', kernel_initializer=init)(gen)\n","    out_layer = Activation('tanh')(gen)\n","\n","    model = Model([in_lat, in_label], out_layer)\n","    return model"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":2651,"status":"ok","timestamp":1595106112549,"user":{"displayName":"sajjad savoji","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjicafS5-Ep5AreuuDxBM5Yk0bzzzKRXLzO8uc=s64","userId":"01019297866349987175"},"user_tz":-270},"id":"2JcnmKF9zTcU"},"outputs":[],"source":["def define_gan(g_model, d_model):\n","\td_model.trainable = False\n","\tgan_output = d_model(g_model.output)\n","\tmodel = Model(g_model.input, gan_output)\n","\topt = Adam(lr=0.0002, beta_1=0.5)\n","\tmodel.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=opt)\n","\treturn model"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":2649,"status":"ok","timestamp":1595106112550,"user":{"displayName":"sajjad savoji","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjicafS5-Ep5AreuuDxBM5Yk0bzzzKRXLzO8uc=s64","userId":"01019297866349987175"},"user_tz":-270},"id":"fcTfqYFh5UIS"},"outputs":[],"source":["def load_real_samples():\n","    # load dataset\n","    (trainX, trainy), (testX, testy) = cifar10.load_data()\n","\n","    X = np.concatenate((trainX, testX))\n","    Y = np.concatenate((trainy, testy))\n","    X = X.astype('float32')\n"," \n","    X = (X - 127.5) / 127.5\n","    Y = to_categorical(Y)\n","    print(X.shape, Y.shape)\n","    return [X, Y]\n","\n","def generate_real_samples(dataset, n_samples):\n","\timages, labels = dataset\n","\tix = randint(0, images.shape[0], n_samples)\n","\tX, labels = images[ix], labels[ix]\n","\ty = ones((n_samples, 1))\n","\treturn [X, labels], y\n","\n","def denorm(x):\n","  out = (x + 1) / 2\n","  return out.clamp(0, 1)\n","\n","def generate_latent_points(latent_dim, n_samples, n_classes=10, uniform=False):\n","    x_input = randn(latent_dim * n_samples)\n","    z_input = x_input.reshape(n_samples, latent_dim)\n"," \n","    if not uniform:\n","        labels = randint(0, n_classes, n_samples)\n","    else:\n","        labels = np.array([[j for j in range(int(n_samples/n_classes))] for i in range(n_classes)]).reshape(-1, 1)\n","    labels = to_categorical(labels, num_classes=n_classes)\n","    return [z_input, labels]\n","\n","def generate_fake_samples(generator, latent_dim, n_samples, uniform=False):\n","\tz_input, labels_input = generate_latent_points(latent_dim, n_samples, uniform=uniform)\n","\timages = generator.predict([z_input, labels_input])\n","\ty = zeros((n_samples, 1))\n","\treturn [images, labels_input], y\n","\n","class_names = ['airplane','car','bird','cat','deer',\n","               'dog','frog','horse','ship','truck']\n","def summarize_performance(step, g_model, latent_dim, n_samples=100):\n","    fig = pyplot.figure(figsize=(10,10))\n","    fig.suptitle(f'epoch {step}')\n","    [X, _], _ = generate_fake_samples(g_model, latent_dim, n_samples, uniform=True)\n","    # scale from [-1,1] to [0,1]\n","    X = (X + 1) / 2.0\n","    for i in range(100):\n","     \n","        pyplot.subplot(10, 10, 1 + i)\n","        pyplot.axis('off')\n","        pyplot.imshow(X[i, :, :, :])\n","        if i < 10:\n","            pyplot.title(class_names[i])\n","    \n","    pyplot.show()\n","    filename1 = 'image_generated_plot_%04d.png' % (step+1)\n","    pyplot.savefig(filename1)\n","    pyplot.close()\n","    # save the generator model\n","    # filename2 = 'model_%04d.h5' % (step+1)\n","    # g_model.save(filename2)\n","    # print('>Saved: %s and %s' % (filename1, filename2))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":2644,"status":"ok","timestamp":1595106112550,"user":{"displayName":"sajjad savoji","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjicafS5-Ep5AreuuDxBM5Yk0bzzzKRXLzO8uc=s64","userId":"01019297866349987175"},"user_tz":-270},"id":"q7rBjVZA6eft"},"outputs":[],"source":["# train the generator and discriminator\n","def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=2, n_batch=100, history=None):\n","   \n","    if history is None:\n","        history = {'dr1':[], 'dr2':[], 'df1':[], 'df2':[], 'g1':[], 'g2':[]}\n","    \n","    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n","    \n","    n_steps = bat_per_epo\n","   \n","    half_batch = int(n_batch / 2)\n","    \n","    for e in range(n_epochs):\n","        \n","        print(f'epoch: {e+1}')\n","        progbar = Progbar(target=n_steps)\n","        for i in range(n_steps):\n","           \n","            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n","           \n","            _,d_r1,d_r2 = d_model.train_on_batch(X_real, [y_real, labels_real])\n","\n","            [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","\n","            _,d_f,d_f2 = d_model.train_on_batch(X_fake, [y_fake, labels_fake])\n","\n","            [z_input, z_labels] = generate_latent_points(latent_dim, n_batch)\n","\n","            y_gan = ones((n_batch, 1))\n","\n","            _,g_1,g_2 = gan_model.train_on_batch([z_input, z_labels], [y_gan, z_labels])\n","\n","            progbar.update(i, [('dr1', d_r1), ('dr2', d_r2), ('df1', d_f), ('df2', d_f2), ('g1', g_1), ('g2', g_2)])\n","            history['dr1'].append(d_r1)\n","            history['dr2'].append(d_r2)\n","            history['df1'].append(d_f)\n","            history['df2'].append(d_f2)\n","            history['g1' ].append(g_1)\n","            history['g2' ].append(g_2)\n","            # print('>%d, dr[%.3f,%.3f], df[%.3f,%.3f], g[%.3f,%.3f]' % (i+1, d_r1,d_r2, d_f,d_f2, g_1,g_2))\n","            # evaluate the model performance every 'epoch'\n","        summarize_performance(e+1, g_model, latent_dim)\n","    return history"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":11892,"status":"ok","timestamp":1595106121810,"user":{"displayName":"sajjad savoji","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjicafS5-Ep5AreuuDxBM5Yk0bzzzKRXLzO8uc=s64","userId":"01019297866349987175"},"user_tz":-270},"id":"zNBU0whRAHWM","outputId":"347e0311-505f-404c-a0cd-5947602a4e78"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\ALI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\initializers\\initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 16, 16, 16)   448         ['input_1[0][0]']                \n","                                                                                                  \n"," leaky_re_lu (LeakyReLU)        (None, 16, 16, 16)   0           ['conv2d[0][0]']                 \n","                                                                                                  \n"," dropout (Dropout)              (None, 16, 16, 16)   0           ['leaky_re_lu[0][0]']            \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 16, 16, 32)   4640        ['dropout[0][0]']                \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 16, 16, 32)  128         ['conv2d_1[0][0]']               \n"," alization)                                                                                       \n","                                                                                                  \n"," leaky_re_lu_1 (LeakyReLU)      (None, 16, 16, 32)   0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 16, 16, 32)   0           ['leaky_re_lu_1[0][0]']          \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 8, 8, 64)     18496       ['dropout_1[0][0]']              \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," leaky_re_lu_2 (LeakyReLU)      (None, 8, 8, 64)     0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 8, 8, 64)     0           ['leaky_re_lu_2[0][0]']          \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 8, 8, 128)    73856       ['dropout_2[0][0]']              \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 8, 8, 128)   512         ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," leaky_re_lu_3 (LeakyReLU)      (None, 8, 8, 128)    0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 8, 8, 128)    0           ['leaky_re_lu_3[0][0]']          \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 4, 4, 256)    295168      ['dropout_3[0][0]']              \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," leaky_re_lu_4 (LeakyReLU)      (None, 4, 4, 256)    0           ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 4, 4, 256)    0           ['leaky_re_lu_4[0][0]']          \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 4, 4, 128)    295040      ['dropout_4[0][0]']              \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," leaky_re_lu_5 (LeakyReLU)      (None, 4, 4, 128)    0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 4, 4, 128)    0           ['leaky_re_lu_5[0][0]']          \n","                                                                                                  \n"," flatten (Flatten)              (None, 2048)         0           ['dropout_5[0][0]']              \n","                                                                                                  \n"," dense (Dense)                  (None, 1)            2049        ['flatten[0][0]']                \n","                                                                                                  \n"," dense_1 (Dense)                (None, 10)           20490       ['flatten[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 712,619\n","Trainable params: 711,403\n","Non-trainable params: 1,216\n","__________________________________________________________________________________________________\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\ALI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}],"source":["# size of the latent space\n","latent_dim = 100\n","# create the discriminator\n","discriminator = define_discriminator()\n","discriminator.summary()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":690},"colab_type":"code","executionInfo":{"elapsed":11882,"status":"ok","timestamp":1595106121812,"user":{"displayName":"sajjad savoji","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjicafS5-Ep5AreuuDxBM5Yk0bzzzKRXLzO8uc=s64","userId":"01019297866349987175"},"user_tz":-270},"id":"L9qMQ6PeAMok","outputId":"1db84323-f193-4c9d-cc54-6c284ba4f661"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_3 (InputLayer)           [(None, 100)]        0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 10)]         0           []                               \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 110)          0           ['input_3[0][0]',                \n","                                                                  'input_2[0][0]']                \n","                                                                                                  \n"," dense_2 (Dense)                (None, 384)          42624       ['concatenate[0][0]']            \n","                                                                                                  \n"," activation (Activation)        (None, 384)          0           ['dense_2[0][0]']                \n","                                                                                                  \n"," reshape (Reshape)              (None, 1, 1, 384)    0           ['activation[0][0]']             \n","                                                                                                  \n"," conv2d_transpose (Conv2DTransp  (None, 2, 2, 192)   1843392     ['reshape[0][0]']                \n"," ose)                                                                                             \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 2, 2, 192)   768         ['conv2d_transpose[0][0]']       \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_1 (Activation)      (None, 2, 2, 192)    0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," conv2d_transpose_1 (Conv2DTran  (None, 8, 8, 96)    460896      ['activation_1[0][0]']           \n"," spose)                                                                                           \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 8, 8, 96)    384         ['conv2d_transpose_1[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_2 (Activation)      (None, 8, 8, 96)     0           ['batch_normalization_6[0][0]']  \n","                                                                                                  \n"," conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 3)   7203        ['activation_2[0][0]']           \n"," spose)                                                                                           \n","                                                                                                  \n"," activation_3 (Activation)      (None, 32, 32, 3)    0           ['conv2d_transpose_2[0][0]']     \n","                                                                                                  \n","==================================================================================================\n","Total params: 2,355,267\n","Trainable params: 2,354,691\n","Non-trainable params: 576\n","__________________________________________________________________________________________________\n"]}],"source":["# create the generator\n","generator = define_generator(latent_dim)\n","generator.summary()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":726},"colab_type":"code","executionInfo":{"elapsed":11872,"status":"ok","timestamp":1595106121814,"user":{"displayName":"sajjad savoji","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjicafS5-Ep5AreuuDxBM5Yk0bzzzKRXLzO8uc=s64","userId":"01019297866349987175"},"user_tz":-270},"id":"Q2FYvZAjAb-q","outputId":"2543b669-36b3-4bdd-c4a7-b73a7443d8f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_3 (InputLayer)           [(None, 100)]        0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 10)]         0           []                               \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 110)          0           ['input_3[0][0]',                \n","                                                                  'input_2[0][0]']                \n","                                                                                                  \n"," dense_2 (Dense)                (None, 384)          42624       ['concatenate[0][0]']            \n","                                                                                                  \n"," activation (Activation)        (None, 384)          0           ['dense_2[0][0]']                \n","                                                                                                  \n"," reshape (Reshape)              (None, 1, 1, 384)    0           ['activation[0][0]']             \n","                                                                                                  \n"," conv2d_transpose (Conv2DTransp  (None, 2, 2, 192)   1843392     ['reshape[0][0]']                \n"," ose)                                                                                             \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 2, 2, 192)   768         ['conv2d_transpose[0][0]']       \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_1 (Activation)      (None, 2, 2, 192)    0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," conv2d_transpose_1 (Conv2DTran  (None, 8, 8, 96)    460896      ['activation_1[0][0]']           \n"," spose)                                                                                           \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 8, 8, 96)    384         ['conv2d_transpose_1[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_2 (Activation)      (None, 8, 8, 96)     0           ['batch_normalization_6[0][0]']  \n","                                                                                                  \n"," conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 3)   7203        ['activation_2[0][0]']           \n"," spose)                                                                                           \n","                                                                                                  \n"," activation_3 (Activation)      (None, 32, 32, 3)    0           ['conv2d_transpose_2[0][0]']     \n","                                                                                                  \n"," model (Functional)             [(None, 1),          712619      ['activation_3[0][0]']           \n","                                 (None, 10)]                                                      \n","                                                                                                  \n","==================================================================================================\n","Total params: 3,067,886\n","Trainable params: 2,354,691\n","Non-trainable params: 713,195\n","__________________________________________________________________________________________________\n"]}],"source":["# make ac_gan model\n","gan_model = define_gan(generator, discriminator)\n","gan_model.summary()"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"colab_type":"code","executionInfo":{"elapsed":16275,"status":"ok","timestamp":1595106126228,"user":{"displayName":"sajjad savoji","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjicafS5-Ep5AreuuDxBM5Yk0bzzzKRXLzO8uc=s64","userId":"01019297866349987175"},"user_tz":-270},"id":"9Un-A7u9u1up","outputId":"c5c1c9b0-c38e-4a2c-86ca-a8fe943713e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["(60000, 32, 32, 3) (60000, 10)\n"]}],"source":["# make history\n","history = {'dr1':[], 'dr2':[], 'df1':[], 'df2':[], 'g1':[], 'g2':[]}\n","# load image data\n","dataset = load_real_samples()\n","epochs = 500"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1S4VV8Wend__AVYWZZ6G96ColBpU9B5YK"},"colab_type":"code","executionInfo":{"elapsed":2048057,"status":"error","timestamp":1595108158020,"user":{"displayName":"sajjad savoji","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjicafS5-Ep5AreuuDxBM5Yk0bzzzKRXLzO8uc=s64","userId":"01019297866349987175"},"user_tz":-270},"id":"VWLKkqp6u1qt","outputId":"dbf64146-ae69-4c4c-9e6b-69bddecd0959"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["# train model\n","history = train(generator, discriminator, gan_model, dataset, latent_dim, n_epochs=epochs, history=history)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPbzZu+7okV04wLPIqmriLP","collapsed_sections":[],"name":"NNDL_miniproj3_ACGAN.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
